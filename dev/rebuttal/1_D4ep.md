# Reviewer (D4ep, rating: 7 `accept')

We thank the reviewer very much for their thoughtful review. 

## Lack of distinct prescription

The main weakness pointed out by the reviewer is that the paper '[...] lacks a distinct prescription beyond a call for AI researchers to be more cautious [...]'. We fall short of doing so in the paper mostly for scope reasons. Where possible we will add a paragraph either in the body or the appendix. In the meantime, we try to answer your specific questions below:

> " [...] if we assume that tearing down the whole publishing incentive structure is beyond the pale, what distinct steps can researchers actually take when experimenting, writing, reviewing and publishing?"

Short of tearing things down entirely, we do think that specific changes to the incentive structure are in order. It has been argued elsewhere that societally impactful scientific insights should be treated as open-source software artifacts ([Liem and Demetriou, 2023](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10173886)). Open review platforms like this one are a step in the right direction but we could go further. In the open-source software development space, those who review a piece of software often end up contributing to it, because they face the right incentives: not only will they most likely be users of that improved piece of software but also receive credit for their contribution (as they should). The idea of moving from authorship to contributorship is not as radical as it may sound ([Smith, 1997](https://www.bmj.com/content/315/7110/696.short)) but thirty years ago one could have argued that we are lacking the right technology for this. Today this argument is much harder to buy in the face of blossoming open-source software ecosystems. Considering that researchers in the computer science field are no strangers to papers with long author lists, we think it is reasonable to assume they would generally welcome such a paradigm shift. 

> "Should we be more welcoming of negative results?" 

Continuing the argument above, a system that leans more towards contributorship is typically much more welcoming of negative results: software bugs are just part of the process and joint ownership means joint responsibility for positive and negative outcomes.
 
> "Should we set up more venues specifically devoted to reproducing and analyzing past claims?"

Yes, we think that reproducibility challenges, for example, are a step in the right direction. But many legacy issues associated with treating 

> "Should we offer compensation for reviewing?" 

Contributorship can provide a natural form of non-pecuniary compensation for reviewing (open-source communities testify to this). As researchers, we are financially compensated for producing research. Perhaps we simply need to get to a point where reviews can lead to (accredited) contributorship. Reviewer awards are a step in the right direction. But given the sheer size of today's venues, they are an improbable, risky outcome for reviewers and hence unlikely to provide strong enough incentives.  

> "All these questions have been asked before, but do they become more salient or more urgent with respect to modern evolutions in generative AI?"

Considering that the existing incentive structure has repeatedly moved researchers to employ generative AI to deal with the tasks and pressures they are facing, we think these questions have certainly become more urgent. 