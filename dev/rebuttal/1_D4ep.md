The main weakness pointed out by the reviewer is that the paper '[...] lacks a distinct prescription beyond a call for AI researchers to be more cautious [...]'. We fall short of doing so in the paper mostly for reasons of scope and scale. Where possible we will add a paragraph either in the body, which is limited by the page limit, or the appendix. In the meantime, we try to answer your specific questions below:

## Distinct Steps

Short of tearing things down, we think that specific changes to the incentive structure are in order. It has been argued elsewhere that societally impactful scientific insights should be treated as open-source software artifacts ([Liem and Demetriou, 2023](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10173886)). Open review platforms like this one are a step in the right direction but we could go further. With open-source software, those who review software often end up contributing to it, because they face the right incentives: not only will they get better software but also receive credit for their contribution. The idea of moving from authorship to contributorship is neither new ([Smith, 1997](https://www.bmj.com/content/315/7110/696.short)) nor technologically infeasible.

## Negative Results

Continuing the argument above, a system that leans more towards contributorship is typically much more welcoming of negative results: software bugs are just part of the process and joint ownership means joint responsibility for positive and negative outcomes.
 
## Reproducibility

Yes, we think that reproducibility challenges, for example, are a step in the right direction.

## Compensation

Contributorship can provide a natural form of non-pecuniary compensation for reviewing (open-source communities testify to this). As researchers, we are financially compensated for producing research. Perhaps we need to get to a point where reviews can lead to (accredited) contributorship. Reviewer awards are a step in the right direction. But given the sheer size of today's venues, they are an improbable, risky outcome for reviewers and hence unlikely to provide strong enough incentives.  

## Urgency

Considering that the existing incentive structure has repeatedly moved researchers to employ generative AI to deal with the tasks and pressures they are facing, we think these questions have certainly become more urgent. 
