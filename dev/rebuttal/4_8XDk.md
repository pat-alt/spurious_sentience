## Other Works

It was not so much the work by Gurnee and Tegmark itself but the subsequent buzz around it on social media that catalyzed this work. We explain that public perception of the state of AI work has been shown to be mediated via experts (e.g. [Neri et al., 2020](https://link.springer.com/article/10.1007/s00146-019-00924-9). We explain that the situation is ripe for over-interpretation to show that expert perceptions are susceptible to cognitive biases, and have downstream consequences.

The paper itself, in particular the revised version, is much more cautious about drawing premature conclusions than some of the public communications that followed (we cite both versions explicitly in the paper). Many related works are also free of grandiose conclusions and instead highlight the benefits of mechanistic interpretability that we also acknowledge in our work (e.g. [Nanda et al., 2023](https://arxiv.org/pdf/2309.00941.pdf); [Gurnee et al., 2023](https://arxiv.org/pdf/2305.01610.pdf); [Li et al., 2023](https://arxiv.org/pdf/2210.13382.pdf)).

Another related field investigates the capacity of LLMs to reason causally. Here, too, there is an opportunity to over-interpret the finding of causal knowledge as causal understanding. Recent work has shown that LLMs can indeed correctly predict causal relationships and this may have practical use cases ([Kıcıman et al., 2023](https://arxiv.org/abs/2305.00050)). But it has also been argued and demonstrated that current LLMs are mere ‘weak causal parrots’ ([Zečević et al., 2023](https://arxiv.org/abs/2308.13067)).

## Social Science Review

Present work resulted from an interdisciplinary team with backgrounds in the computational and social sciences. By including a social science review we strengthen our argument that the risks of bias and over-interpretation in humans have consistently been evidenced in academic literature (as opposed to merely stating our opinion on the matter). Still, we recognize that drawing connections between fields is always challenging in interdisciplinary works and we will try to address this in the manuscript through additional references between both parts of the paper. 

We hope that our review can help researchers in the ML community (ourselves included) to be more aware of our human tendencies to seek patterns and to anthropomorphize. While these tendencies are often useful, they can also harm communities, perhaps especially research communities, and bias public perception.
