# Reviewer 4 (8XDk, rating: 4 `borderline reject')

We thank the reviewer for the detailed and thoughtful review. 

## Other Works

It was not so much the work by Gurnee and Tegmark itself but the subsequent buzz around it on social media that served as a catalyst for this work. Further, we explain that public perception of the state of AI work has been shown to be mediated via experts (e.g. [Neri et al., 2020](https://link.springer.com/article/10.1007/s00146-019-00924-9). We explain that the situation is ripe for over-interpretation to show that expert perceptions are susceptible to cognitive biases, and have downstream consequences. 

The paper itself, in particular the revised version, is much more cautious about drawing premature conclusions than some of the public communications that followed (we cite and refer to both versions explicitly in the paper). Many related works are also free of grandiose conclusions and instead highlight the benefits of mechanistic interpretability that we also acknowledge in our work (e.g. [Nanda et al., 2023](https://arxiv.org/pdf/2309.00941.pdf); [Gurnee et al., 2023](https://arxiv.org/pdf/2305.01610.pdf); [Li et al., 2023](https://arxiv.org/pdf/2210.13382.pdf)). But as we explain in the paper, certain incentives and pressures may lead researchers to blow their scientific findings out of proportion outside of academia itself. The general situation surrounding LLMs makes biased interpretations of results particularly likely. And if experts over-interpret their findings, public perception will be influenced by this as well. This is what we want to caution against and why we call for more explicit acknowledgment of known limitations, stronger tests and more epistemologically robust standards.

Another broadly related field investigates the capacity of LLMs to reason causally. Here, too, there is an opportunity to over-interpret the finding of causal knowledge as causal understanding. Recent work has shown that LLMs can indeed correctly predict causal relationships and this may have practical use cases ([Kıcıman et al., 2023](https://arxiv.org/abs/2305.00050)). But it has also been argued and demonstrated that current LLMs are mere ‘weak causal parrots’ ([Zečević et al., 2023](https://arxiv.org/abs/2308.13067)).

## Guidance from the Social Science(s) 

We appreciate the points raised here by the reviewer, in particular, that “the sudden pivot to the social science literature review” caused confusion. Drawing these kinds of connections is always challenging in interdisciplinary works and we will try to address this in the manuscript. In particular, with respect to the experiments, we will make it more clear that:

We would not expect that anyone would anthropomorphize simple random projections and PCA, although both can be used to distill meaningful representations.
And yet, researchers do fall into that trap for more sophisticated models, in particular LLMs. 

> “Could you clarify how the social science review provides guidance for the ML community with respect to your specific experiments and more broadly?”

Present work resulted from an interdisciplinary team with backgrounds in the computational and social sciences. By including a social science review we strengthen our argument that the risks of bias and over-interpretation in humans have consistently been evidenced in academic literature (as opposed to merely stating our opinion on the matter). 

At the very least, we hope that our review can help researchers in the ML community (ourselves included) to become more aware of our human tendencies to seek patterns and confirmation and to anthropomorphize. While these tendencies are often useful, they can also harm communities, perhaps especially research communities, and bias public perception. Further, we hope that, through acknowledgment that all humans are subject to cognitive bias and that the current situation in AI research in general, and with LLMs in particular, is ripe for at least two forms of bias, a focus can be placed on combating it through more severe tests of AGI-related hypotheses, and research design. 
